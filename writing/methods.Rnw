\documentclass[11pt]{article}
\usepackage{geometry} 

\geometry{letterpaper, top=1.5cm, left=2cm}                
\usepackage{graphicx}
\usepackage{amssymb, amsmath}
\usepackage{epstopdf}
\DeclareGraphicsRule{.tif}{png}{.png}{`convert #1 `dirname #1`/`basename #1 .tif`.png}

\renewcommand{\familydefault}{cmss}

\usepackage{setspace}
\onehalfspacing

\title{Methods for real-time forecasting}
\author{Stephen Lauer, Nicholas G. Reich, Krzysztof Sakrejda  [for now, alphabetical by last name]}

\begin{document}
\maketitle

\section{Introduction}

Producing accurate and actionable forecasts of infectious disease incidence at short and long time scales could improve public health response to outbreaks. Infectious diseases have several characteristics that enable researchers to construct viable forecasting models. 

First, they often (although not always) follow seasonal patterns. Seasonal cycles may be due to different factors that enhance disease transmission. For example, with influenza cold and dry weather has been shown to enhance transmission. Possible explanations for this phenomenon include the virus surviving longer in these conditions and a weakening of human defenses (e.g. mucus membranes become fragile and chapped). For vector-borne diseases, such as malaria, dengue fever, or lyme disease, climactic conditions determine the activity of the disease vector and therefore the rate of disease transmission. Additionally, cultural and social factors can drive disease transmission in predicable ways by increasing or decreasing social contacts around known social events such as school vacations or holiday celebrations, to name a few.

With the maturation of disease surveillance and reporting systems in recent years, real-time disease forecasting has become a realistic goal in certain settings. Recognizing the importance of this emerging field, several governmental agencies have established contests, with the goal to have contestants produce accurate forecasting results. However, researchers and practitioners are still working to understand and establish a set of best practices for conducting real-time forecasting. 

In 2014, our research team, in collaboration with Thailand's Ministry of Public Health, established a procedure for generating real-time forecasts of dengue fever, based on current disease surveillance reports from Thailand.

This manuscript (1) documents the process and methods used to collect, process, and use the data for disease forecasting, (2) presents preliminary results of real-time forecasting of dengue fever in Thailand for the year 2014, and (3) provides a template for the documentation, reporting, and validation of real-time disease forecasts. 

\section{Forecasting methods}

\subsection{Data}
The data presented here comes from the Thai surveillance system, run by the Ministry of Public Health in Nonthaburi, Thailand. Monthly DHF case counts for each province are available from January 1968 through December 2005. Individual case reports (hereafter referred to as ``line-list'' data) are available for DF, DHF, and DSS from January 1, 1999 through the present time (this is the format of the real-time data). The line-list data has information on each particular case, including date of symptom onset, home address-code of the case (similar to a U.S. zip code), disease diagnosis code, and demographic information (sex, marital status, age, etc...). In years where we have overlaping sources for case data, the line-list data is used.

Because the generation time of dengue fever is about two weeks, we chose to model the data on a bi-weekly timescale. Therefore, we aggregate the line-list data into biweekly intervals (see biweek definition below) and interpolate the monthly counts into biweekly counts. The latter interpolation is performed by fitting a monotonically increasing smooth spline to the cumulative case counts in each province, and then taking the differences between the estimated cumulative counts at each interval as the number of incident cases in a given interval.

We chose to use only DHF cases in our modeling for several reasons: (1) DHF is the only disease reported consistently across the 47 years of data collection, (2) DHF is less likely than DF to be misdiagnosed or to be differentially misclassified over time, and (3) from a public health perspective, DHF is a more relevant outcome, as it is a life-threatening condition and requires medical attention.

\subsection{Reporting delays}
In constructing real-time forecasts, understanding what data is available at each particular time is a vitally important part of the data exploration process. It can be difficult or impossible to glean from static, historical records of disease incidence (such as, e.g., annual reports that contain weekly incidence numbers), what data were available at a particular time. The process of reporting case data varies widely depending on the surveillance system in question. 

A key variable of interest that can characterize a surveillance system is the reporting delay, defined for our purposes as the duration of time between symptom onset and the case being available for analysis. For systems with largely digital record keeping, the reporting delays may be minimal, and largely be due only to the time it takes individuals to present with symptoms at a doctor's office, clinic, or hospital. In other surveillance systems, the path of data from local clinic to national surveillance system may require weeks or months. In the U.S., influenza cases aggregated in surveillance data managed by the Centers for Disease Control and Prevention (CDC) have between two and four week reporting delays. In the Thai surveillance system for dengue, we have observed between two week and [[XX]] month reporting delays. This is due to the process of reporting cases in which case data moves from local clinics to a provincial health office and then to the national surveillance center. We have observed that in all provinces, 75\% of cases are reported within 3 months. However, a small fraction of cases can take quite a bit longer, due to administrative or other delays.

Measuring reporting delays and examining how they vary across time and space is an are of research that we are working on analyzing, and hope to incorporate in future forecasting models of dengue fever, as informing an observation process model.

\subsection{Real-time data management}
We have established a secure data transfer process to transmit data from the Thai disease surveillance system to U.S. researchers, so that the data may be easily used to generate forecasts. Thai public health officials transmit data every two weeks to a secure server based in the U.S. These data are then loaded into a PostgreSQL database that contains all data, including a table of the monthly case counts and a table with all line-lists received to date. Currently, this database holds records of 2.5 million unique cases of dengue in Thailand for the years 1968 through 2014. Close to 2 million of those records are DHF cases.

For cases with symptom onset in 2014, each unique case record is timestamped with a ``delivery date'' when it first is transmitted in a data transfer and is available in the SQL database. This enables us to ``turn back the clock'', i.e. to query data that was available at a particular point in time. This is important for being able to retrospectively assess the performance of models as if they were applied in real-time. Since all case reports have some delay between symptom onset and their delivery date, case counts would be different for the queries "all cases with symptom onset prior to 2014-04-01" and "all cases with delivery date prior to 2014-04-01". For prospective forecasting, we will only ever have the cases with delivery date prior to the current time, so it is vital to be able to query the database in this fashion to return datasets for analysis that provide only the available cases at a particular time. In surveillance systems that may have a much shorter time between symptom onset and case report (e.g. Singapore's all-digital surveillance system reportedly has minimal reporting delays for cases [cite Rocklov? Althouse?]) this concern may be less of an issue. But as described above, reporting delays in the Thai surveillance system differ by province, and case reports may take months to find their way into the official surveillance record. Therefore, having a system that measures these delays systematically and can base forecasts on data available at a particular time play a vital role in creating and evaluating forecasts.

\section{Notation and timeline for real-time forecasts}

For a given year, every date is mapped to a particular biweek in that year. We define the first biweek of every year as beginning on January 1st, at 00h00m00s and the last as ending on December 31st, 11h59m59s. Every year is defined to contain exactly 26 biweeks. To make predictions on the biweekly scale, daily case counts are aggregated into their respective biweek. Counts for biweeks that have 15 days are standardized by multiplying the count by $\frac{14}{15}$ and rounding to the nearest integer. The explicit Julian calendar day to biweek mapping is given in Table \ref{tab:biweekMap}.

<<biweekTable, echo=FALSE, results='asis', message=FALSE>>=
library(cruftery)
library(dplyr)
library(xtable)
leap_yr_map <- tbl_df(with(data=environment(date_to_biweek), 
                           expr=return(leap_year_map)))
regular_yr_map <- tbl_df(with(data=environment(date_to_biweek), 
                              expr=return(regular_year_map)))
leap_yr_table <- leap_yr_map %>% 
        group_by(biweek) %>% 
        summarize(leap_yr_start=min(julian_day),
                  leap_yr_end=max(julian_day))
regular_yr_table <- regular_yr_map %>% 
        group_by(biweek) %>% 
        summarize(reg_yr_start=min(julian_day),
                  reg_yr_end=max(julian_day))
biweek_table <- inner_join(leap_yr_table, regular_yr_table)
biweek_table <- biweek_table %>%
        mutate(reg_yr_datestart = format(as.Date(paste0(biweek_table$reg_yr_start,"-2011"), 
                                                 format="%j-%Y"), "%b %d"),
               reg_yr_dur = reg_yr_end-reg_yr_start+1,
               leap_yr_datestart = format(as.Date(paste0(biweek_table$leap_yr_start,"-2012"), 
                                                 format="%j-%Y"), "%b %d"),
               leap_yr_dur = leap_yr_end-leap_yr_start+1) %>%
        select(-contains("_start"), -contains("_end"))
print(xtable(biweek_table, digits=0, align="cccccc", label="tab:biweekMap",
             caption="Map of Julian days to biweeks used in data aggregation."), 
      include.rownames=FALSE, caption.placement="top")
@


A generic biweek $b_k$ is defined as an interval $[t_{k}, t_{k+1})$ where $t_k$ is the time where the biweeks begins (e.g. Jan 1, 00h00m00s) and $t_{k+1}$ is the start of the next biweek. Every dataset is divided up into $N$ bi-weeks ($b_1$ through $b_{N}$), each of either 14 or 15 days (see Table \ref{tab:biweekMap}). 

Every forecast made specifies the following dates: a ``to-date'' ($t_{to}$), a ``delivery-date'' ($t_{del}$), and an ``analysis-date'' ($t_{an}$). The to-date specifies that the current forecast will only use cases whose symptom onset date is equal to or less than $t_{to}$. The delivery-date specifies that the current forecast will only use cases that were delivered on or before $t_{del}$. The analysis-date specifies when a given forecast was run.


A forecast also may specify a biweek lag, $l$, the number of biweeks back into the past data will be ignored. For example, if $l=4$ and $t_{del}$ lies in $b_k=[t_{k}, t_{k+1})$, then the forecast will assume that data for the past $l$ whole biweeks are systematically underreported and that biweek $b_{k-l-1}$ and all prior biweeks are complete.

\begin{figure}[htbp]
\begin{center}
\caption{An example forecast timeline showing which cases are included relative to the delivery-dates and to-dates. In this figure, $l=3$.}
\label{fig:timeline}
\includegraphics[width=\linewidth]{figures/forecast_timeline.png}
\end{center}
\end{figure}


\section{spamd-style model}
The models that we fit to the data are defined as follows. We define the number of cases with onset at time $t$ in province $i$ as $Y_{t,i}$ and assume that
\begin{eqnarray}
Y_{t,i} & \sim & Poisson(\lambda_{t,i} \cdot Y_{t-1,i})
\end{eqnarray}
where the lag-1 term $Y_{t-1,i}$ is used as an offset in this model. Furthermore, we explicitly model the rate $\lambda$ as 
\begin{eqnarray}
\log \lambda_{t,i} & = & f(t) + \sum_{j\in \mathcal{C}} \sum_{k \in \mathcal{L}} \alpha_{j,k} \log \frac{Y_{t-k,j}+1}{Y_{t-k-1,j}+1} \label{eq:spamd_model}
\end{eqnarray}
where $\mathcal{C}$ is the set of $J$ most-correlated provinces with province $i$ and $\mathcal{L}$ is the set of lag times used in the model. Additionally $f(t)$ is assumed to be a cyclical cubic spline.

We note that the model can be expressed as 
$$\log \mathbb{E}[Y_{t,i}] = \log \lambda_{t,i} + \log Y_{t-1,i}$$
which also defines $\lambda$ as the factor by which the prior week's case counts are scaled to equal the current weeks case counts. Due to the inclusion of the lag-1 offset term $\lambda$ is interpreted as the ratio of the current biweek to the previous biweek. While this is a valid interpretation and model for the data, it is also slightly different from common models for $\lambda$ that do not have a lag-1 offset.

Other versions of spamd models use the following alternative model for $\lambda$:
\begin{eqnarray}
\log \lambda_{t,i} & = & f(t) + \sum_{j\in \mathcal{C}} \sum_{k \in \mathcal{L}} \alpha_{j,k} \log (Y_{t-k,j}+1)
\end{eqnarray}

These models are fit using the Generalized Additive Model (GAM) framework, using a penalized cyclic spline with period of one year to estimate $f(t)$. 

\section{Simulating predicted counts}
To generate predicted counts for future unobserved timepoints, we create stochastic realizations of possible trajectories for each province. For example, if data through time $t$ is used to fit the models for all locations, then a single realization consists of a simulated Markov chain of dependent observations for time points $t+1$, $t+2$, ..., $t+N$, across all provinces. Due to the interrelations between the provinces, as shown in equation \ref{eq:spamd_model}, we simulate counts for all provinces at a single timepoint before moving on to the next timepoint. For a single province and timepoint, an observation is created by drawing from a Poisson distribution with mean given by equation \ref{eq:spamd_model}. Assuming we generate observations for $L$ locations and $N$ timepoints, a single realization consists of $L$ province-level observations at $N$ timepoints, or $L \cdot N$ total observations. This process is repeated $M$ times, to create $M$ separate future possible realizations or trajectories. For a given province and timepoint, this creates an empirical posterior predictive distribution. With $M$ sufficiently large, this distribution can be used to construct prediction intervals for each province-timepoint.


\section{Outbreak probabilities}
We use the empirical posterior predictive distribution to calculate the probability that a location is experiencing an outbreak at timepoint $t+m$. An outbreak is defined as incident cases being larger than a specified number of standard deviations ($r$, set to 2 by default) above a seasonal baseline for a particular province. This a commonly used strategy for defining infectious disease outbreaks, first introduced by Serfling for modeling seasonal influenza in the US [[cite]], and subsequently used in numerous other settings [[cite others]]. To define our seasonal baseline, we use a method that mirrors the process used by the Thai MoPH in previous years. For each biweek $b$, we compute the mean and standard deviation and for the number of cases in that biweek over the past 8 years, leaving out the highest and lowest observations for that biweek. The epidemic threshold for biweek $b$ is defined as the mean plus two times the standard deviation.

%use the GAM framework to fit a model with two smooth functions of time to the observed data from each province. The first component is a penalized spline to capture secular trends across the entire time observed. The second component is a smooth cyclic penalized spline (with period of 1 year). A log-linear quasi-Poisson model is fit to the data, with the number of observed cases as the outcome variable and the two penalized splines as the only independent predictors. We say that these baseline seasonal values are $\hat Y_{t,i}$ In addition to estimating the penalized splines themselves, this method also estimates the dispersion of the quasi-Poisson distribution, $\xi$. We compute the the expected standard deviation of this baseline seasonal model at time $t$ to be $\sqrt{\hat Y_{t,i}\cdot \xi}$. Therefore the outbreak threshold is defined to be $O_{t,i} = \hat Y_{t,i} + r\cdot\sqrt{\hat Y_{t,i}\cdot \xi}$, where $r$ is the specified number of standard deviations above baseline to consider an outbreak.

For a given province-timepoint, or ($t,i$) pair, the outbreak probability is calculated as the fraction of the $M$ stochastic realizations greater than $O_{t,i}$.


% gam(y~s(yr)+s(tiy, bs="cc"), 
%     data=data.frame(y=x[i,], yr=x@yr, tiy=x@time.in.yr),
%     family=quasipoisson)
% rc[i,] <- predict(mdl, newdata=proj.data, type="response")
% disp <- summary(mdl)$dispersion
% rc[i,] <- rc[i,]+epi.level*sqrt(rc[i,]*disp)

\end{document}